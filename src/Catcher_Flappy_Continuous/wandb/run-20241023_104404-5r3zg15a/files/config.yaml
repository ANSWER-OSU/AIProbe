_wandb:
    value:
        cli_version: 0.18.5
        code_path: code/Catcher_Flappy_Continuous/cleanrl/cleanrl/dqn.py
        m: []
        python_version: 3.10.15
        t:
            "1":
                - 1
                - 55
            "2":
                - 1
                - 55
            "3":
                - 3
                - 13
                - 16
                - 23
                - 35
                - 55
            "4": 3.10.15
            "5": 0.18.5
            "8":
                - 5
            "12": 0.18.5
            "13": darwin-arm64
batch_size:
    value: 128
buffer_size:
    value: 100000
capture_video:
    value: false
cuda:
    value: true
end_e:
    value: 0.05
env_id:
    value: FlappyBird
exp_name:
    value: dqn
exploration_fraction:
    value: 0.5
gamma:
    value: 0.9
hf_entity:
    value: ""
learning_rate:
    value: 0.00025
learning_starts:
    value: 10000
num_envs:
    value: 1
save_model:
    value: true
seed:
    value: 1
start_e:
    value: 1
target_network_frequency:
    value: 500
tau:
    value: 1
torch_deterministic:
    value: true
total_timesteps:
    value: 5000000
track:
    value: true
train_frequency:
    value: 10
upload_model:
    value: false
wandb_entity:
    value: null
wandb_project_name:
    value: FlappyBird_DQN
